{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import seaborn as sns\n",
    "import os\n",
    "import wave\n",
    "\n",
    "sns.set(style=\"whitegrid\",color_codes=True)\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams[\"figure.figsize\"] = [16, 12]\n",
    "from subprocess import check_output\n",
    "\n",
    "import chardet\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "from scipy.io import wavfile\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema=StructType([\n",
    "    StructField(\"filename\",StringType(),True),\n",
    "    StructField(\"text\",StringType(),True)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"speech to text\").getOrCreate()\n",
    "sc=spark.sparkContext\n",
    "df=spark.read.csv(\"Trans1.txt\",header=False,schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.randomSplit([0.67,0.33], seed=5)\n",
    "print(df.count())\n",
    "print(df2[0].count())\n",
    "print(df2[1].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Trans1.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Filename'] = df[0].str.split(expand=True)[0]\n",
    "\n",
    "transcriptions = []\n",
    "for i in df[0]:\n",
    "    s = ''\n",
    "    k = i.split()\n",
    "    s = ' '.join(k[1:])\n",
    "    transcriptions.append(s)\n",
    "df['Transcription'] = transcriptions\n",
    "df.drop(0,axis = 1,inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = ' '.join(df['Transcription'])\n",
    "wordcloud2 = WordCloud().generate(string)\n",
    "plt.imshow(wordcloud2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema=StructType([\n",
    "    StructField(\"filename\",StringType(),True),\n",
    "    StructField(\"text\",StringType(),True)\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName(\"speech to text\").getOrCreate()\n",
    "sc=spark.sparkContext\n",
    "df=spark.read.csv(\"Trans2.txt\",header=False,schema=schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Trans2.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Filename'] = df[0].str.split(expand=True)[0]\n",
    "\n",
    "transcriptions = []\n",
    "for i in df[0]:\n",
    "    s = ''\n",
    "    k = i.split()\n",
    "    s = ' '.join(k[1:])\n",
    "    transcriptions.append(s)\n",
    "df['Transcription'] = transcriptions\n",
    "df.drop(0,axis = 1,inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = ' '.join(df['Transcription'])\n",
    "wordcloud2 = WordCloud().generate(string)\n",
    "plt.imshow(wordcloud2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_path = 'LibriSpeech/dev-clean'\n",
    "labels=os.listdir(train_audio_path)\n",
    "\n",
    "all_wave = []\n",
    "all_label = []\n",
    "for label in labels:\n",
    "    print(label)\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/'+ label) if f.endswith('.flac')]\n",
    "    for wav in waves:\n",
    "        samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)\n",
    "        samples = librosa.resample(samples, sample_rate, 8000)\n",
    "        if(len(samples)== 8000) : \n",
    "            all_wave.append(samples)\n",
    "            all_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y=le.fit_transform(all_label)\n",
    "classes= list(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y=np_utils.to_categorical(y, num_classes=len(labels))\n",
    "all_wave = np.array(all_wave).reshape(-1,8000,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#x_tr, x_val, y_tr, y_val = train_test_split(np.array(all_wave),np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "\n",
    "inputs = Input(shape=(8000,1))\n",
    "\n",
    "#First Conv1D layer\n",
    "conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Second Conv1D layer\n",
    "conv = Conv1D(16, 11, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Third Conv1D layer\n",
    "conv = Conv1D(32, 9, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Fourth Conv1D layer\n",
    "conv = Conv1D(64, 7, padding='valid', activation='relu', strides=1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Flatten layer\n",
    "conv = Flatten()(conv)\n",
    "\n",
    "#Dense Layer 1\n",
    "conv = Dense(256, activation='relu')(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#Dense Layer 2\n",
    "conv = Dense(128, activation='relu')(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "outputs = Dense(len(labels), activation='softmax')(conv)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10, min_delta=0.0001) \n",
    "mc = ModelCheckpoint('best_model.hdf5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history=model.fit(x_tr, y_tr ,epochs=100, callbacks=[es,mc], batch_size=32, validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"SK2YZLMPFWFWY2VZMC76IVIDWVHSWWJC\"\n",
    "def transcription(filename):\n",
    "\tr = sr.Recognizer()\n",
    "\twith sr.AudioFile(filename) as source:\n",
    "\t\t#r.adjust_for_ambient_noise(source)\n",
    "\t    audio_data = r.record(source)\n",
    "\t    text = r.recognize_wit(audio_data, key=k)\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeTranscript(filename,content):\n",
    "\twith open(filename,\"a\") as file:\n",
    "\t    file.write(content.upper()+\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    if i<10:\n",
    "        filename = \"flac samples/84-121123-000\"+str(i)+\".flac\"\n",
    "    else:\n",
    "        filename = \"flac samples/84-121123-00\"+str(i)+\".flac\"\n",
    "    t=transcription(filename)\n",
    "    writeTranscript(\"PTrans.txt\",t)\n",
    "    print(\"Full text:\", t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Large Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=\"HXLB4JAVE7QXG3VNU2EF5TSA6KMLUNBG\"\n",
    "def get_large_audio_transcription(path):\n",
    "    \"\"\"\n",
    "    Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\n",
    "    \"\"\"\n",
    "    r = sr.Recognizer()\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_file(path)  \n",
    "    # split audio sound where silence is 700 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 300,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-12,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        with sr.AudioFile(chunk_filename) as source:\n",
    "            audio_listened = r.record(source)\n",
    "            # try converting it to text\n",
    "            try:\n",
    "                text = r.recognize_wit(audio_listened,key=k)\n",
    "            except sr.UnknownValueError as e:\n",
    "                print(\"Error:\", str(e))\n",
    "            else:\n",
    "                text = f\"{text.capitalize()}. \"\n",
    "                print(chunk_filename, \":\", text)\n",
    "                whole_text += text\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "\t#path = \"audio-chunks/sample-00000\"+str(i)+\".mp3\"\n",
    "\tpath = \"flac samples/84-121123-000\"+str(i)+\".flac\"\n",
    "\tprint(\"Full text:\", get_large_audio_transcription(path),end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Trans.txt',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Filename'] = df1[0].str.split(expand=True)[0]\n",
    "\n",
    "transcriptions = []\n",
    "for i in df1[0]:\n",
    "    s = ''\n",
    "    k = i.split()\n",
    "    s = ' '.join(k[1:])\n",
    "    transcriptions.append(s)\n",
    "df1['Transcription'] = transcriptions\n",
    "df1.drop(0,axis = 1,inplace = True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = ' '.join(df1['Transcription'])\n",
    "WC1 = WordCloud().generate(s1)\n",
    "plt.imshow(WC1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('PTrans.txt', header = None)\n",
    "df2['Transcription'] = df2[0]\n",
    "df2.drop(0,axis = 1,inplace = True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = ' '.join(df2['Transcription'])\n",
    "WC2 = WordCloud().generate(s2)\n",
    "plt.imshow(WC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(s):\n",
    "    d = {}\n",
    "    for i in s:\n",
    "        if i in d:\n",
    "            d[i] += 1\n",
    "        else:\n",
    "            d[i] = 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_test(df1, df2):\n",
    "    matches = 0\n",
    "    mismatches = 0\n",
    "    for i in range(len(df2)):\n",
    "            s1 = df1['Transcription'].iloc[i].split()\n",
    "            s2 = df2['Transcription'].iloc[i].split()\n",
    "            l1 = len(s1)\n",
    "            l2 = len(s2)\n",
    "            d1 = word_count(s1)\n",
    "            d2 = word_count(s2)\n",
    "            for k in d1:\n",
    "                if k in d2:\n",
    "                    if d1[k] == d2[k]:\n",
    "                        matches += d1[k]\n",
    "                    else:\n",
    "                        m = max(d1[k], d2[k])\n",
    "                        mismatches += ((m - d1[k]) + (m - d2[k]))\n",
    "            for k in d2:\n",
    "                if k not in d1:\n",
    "                    mismatches += d2[k]\n",
    "    print((matches/(matches+mismatches))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test(df1,df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
